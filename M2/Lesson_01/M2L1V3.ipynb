{
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "notebookId": "3g4msb26g2btd25mcjjb",
   "authorId": "6841714608330",
   "authorName": "CHANINN",
   "authorEmail": "chanin.nantasenamat@snowflake.com",
   "sessionId": "a698651e-2cbb-48cc-b0de-f4569768c9c8",
   "lastEditTime": 1761101626701
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d426b25b-3041-4807-8860-3b18ceb4d77d",
   "metadata": {
    "name": "md_title",
    "collapsed": false
   },
   "source": "# Setup Database, Schema and Stages in Snowflake"
  },
  {
   "cell_type": "markdown",
   "id": "4e34af18-6073-4627-bf9d-926c2bb061af",
   "metadata": {
    "name": "md_setup_notebook",
    "collapsed": false
   },
   "source": "## Prerequisite\n\nInstall prerequisite libraries by clicking on `Packages` drop-down button at the top menu and under the Anaconda Packages tab make sure the following libraries are installed, if not then you can enter them into the text box and click the `Save` button to install:\n- `modin`\n- `snowflake-snowpark-python`\n"
  },
  {
   "cell_type": "markdown",
   "id": "2e6cebea-bf7a-4072-9621-3b7bb298b11c",
   "metadata": {
    "name": "md_create_db_schema",
    "collapsed": false
   },
   "source": "## 1. Create database and schema"
  },
  {
   "cell_type": "code",
   "id": "7703f347-358e-4993-973f-70ac181fdd6b",
   "metadata": {
    "language": "sql",
    "name": "sql_create_db_schema"
   },
   "outputs": [],
   "source": "-- Create avalanche_db database\nCREATE DATABASE IF NOT EXISTS avalanche_db;\n\n-- Create avalanche_schema schema\nCREATE SCHEMA IF NOT EXISTS avalanche_schema;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fccb488c-2e63-4049-a5ed-4d2016c85fea",
   "metadata": {
    "name": "md_set_current_db_schema",
    "collapsed": false
   },
   "source": "### Determine current database and schema\nIn case that we have already created both the `AVALANCHE_DB` database and `AVALANCHE_SCHEMA` schema, we can set these as our working database and schema, otherwise it will default to the database and schema that the notebook is running on."
  },
  {
   "cell_type": "code",
   "id": "1259627c-6af0-4681-8797-b08ef338544c",
   "metadata": {
    "language": "sql",
    "name": "sql_set_current_db"
   },
   "outputs": [],
   "source": "-- Current database that we are using\nSELECT CURRENT_DATABASE();",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "68cdb4a6-8c9c-4376-8686-d2535849c2a3",
   "metadata": {
    "language": "sql",
    "name": "sql_set_current_schema",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Current schema that we are using\nSELECT CURRENT_SCHEMA();",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8556b9b6-de33-46ba-aab9-6a2d3766a885",
   "metadata": {
    "name": "md_set_db_schema",
    "collapsed": false
   },
   "source": "### Set database and schema\n\nAs we expected, if the database and schema have already been created then we are indeed using the same database and schema that the notebook is running on."
  },
  {
   "cell_type": "code",
   "id": "9a80fc0e-9f13-4aeb-95b6-51e2b026224e",
   "metadata": {
    "language": "sql",
    "name": "sql_set_db_schema",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Set database to AVALANCHE_DB\nUSE DATABASE avalanche_db;\n\n-- Set schema to AVALANCHE_SCHEMA\nUSE SCHEMA avalanche_schema;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c2bb8686-4d01-4088-a32c-b5a734ed35a6",
   "metadata": {
    "name": "md_create_stage_load_csv",
    "collapsed": false
   },
   "source": "## 2. Create stage and load CSV data\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "30276ab9-3fef-436e-abbb-0f18d334aea4",
   "metadata": {
    "name": "md_create_stage_s3_csv",
    "collapsed": false
   },
   "source": "### Option 1: Create stage from an S3 bucket\n\nTo create a stage we're using `CREATE STAGE` and we're specifying the `URL` as a path to the S3 bucket which points to `'s3://sfquickstarts/misc/avalanche/csv/'`."
  },
  {
   "cell_type": "code",
   "id": "1294052e-5880-4e61-935b-9dd501e12c08",
   "metadata": {
    "language": "sql",
    "name": "sql_create_stage_s3_csv"
   },
   "outputs": [],
   "source": "-- Create the stage and load CSV files from S3\nCREATE STAGE IF NOT EXISTS avalanche_stage\n  URL = 's3://sfquickstarts/misc/avalanche/csv/'\n  DIRECTORY = (ENABLE = TRUE AUTO_REFRESH = TRUE);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a2e3821-77cc-490d-9215-8a62c18fb4d3",
   "metadata": {
    "name": "md_ls_stage",
    "collapsed": false
   },
   "source": "Let's now check whether these CSV files are loaded properly into the stage."
  },
  {
   "cell_type": "code",
   "id": "a4e506fa-eb53-46f6-aa57-fc116e4b061a",
   "metadata": {
    "language": "sql",
    "name": "sql_ls_stage"
   },
   "outputs": [],
   "source": "-- List files in the stage\nls @avalanche_stage",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "832eee7d-9015-43f1-8303-46bd830a0dcb",
   "metadata": {
    "name": "md_create_stage_then_upload",
    "collapsed": false
   },
   "source": "### Option 2: Create an empty stage, then load files in later\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "01e295ec-ed08-43bb-8851-1ad8bfbb57f7",
   "metadata": {
    "name": "md_create_empty_stage",
    "collapsed": false
   },
   "source": "#### Create an empty stage\n\nIf we prefer to first create an empty stage and then load in the data separately you can follow instructions herein.\n\nIn creating the stage, we're also specifying that the stage be encrypted on the server-side (SSE) and also enabling `DIRECTORY` so that we can see the list of files from the stage."
  },
  {
   "cell_type": "code",
   "id": "534e72d0-1839-4482-970e-89a09f3de2c7",
   "metadata": {
    "language": "sql",
    "name": "sql_create_empty_stage"
   },
   "outputs": [],
   "source": "CREATE STAGE IF NOT EXISTS avalanche_stage -- Use this if you did not run Option 1\n-- CREATE OR REPLACE STAGE avalanche_stage -- Uncomment this if you ran Option 1 (we need to overwrite the previous stage)\n  ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE')\n  DIRECTORY = (ENABLE = true);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7dd18868-7413-47ed-a155-4d743c6027a5",
   "metadata": {
    "name": "md_load_csv_to_stage",
    "collapsed": false
   },
   "source": "#### Load CSV data into the stage\nDownload [customer_reviews.csv](https://github.com/https-deeplearning-ai/fast-prototyping-of-genai-apps-with-streamlit/blob/main/M1/Lesson_03/deploy/customer_reviews.csv) from the GitHub repo.\n\nGo to Snowsight then ...# \n1. Click on the Data icon in the left sidebar and select `Database Explorer`\n2. Navigate to `AVALANCHE_DB` database > `AVALANCHE_SCHEMA` schema > `Stages` > `AVALANCHE_STAGE`\n3. Click on the blue `+ Files` button then in the `Upload Your Files` modal window, click on Browse file or drag and drop the CSV file into the designated area."
  },
  {
   "cell_type": "markdown",
   "id": "95939e90-0572-4bdb-8e0a-19aaf05b8060",
   "metadata": {
    "name": "md_create_df_staged_csv",
    "collapsed": false
   },
   "source": "## 3. Create a DataFrame from staged CSV file"
  },
  {
   "cell_type": "code",
   "id": "dcc58007-2f24-46ed-87ba-2844a379253c",
   "metadata": {
    "language": "python",
    "name": "py_create_df_staged_csv"
   },
   "outputs": [],
   "source": "import modin.pandas as pd\nimport snowflake.snowpark.modin.plugin\n\ndf = pd.read_csv('@AVALANCHE_STAGE/customer_reviews.csv')\ndf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c22eda45-fab8-4623-9e4d-4f7f80a376cd",
   "metadata": {
    "name": "md_write_to_table",
    "collapsed": false
   },
   "source": "## 4. Write to a Snowflake table\n\nHere, we're writing to a Snowflake table called `customer_reviews`"
  },
  {
   "cell_type": "code",
   "id": "744c22c6-013c-435a-bf3a-1c20534d92cd",
   "metadata": {
    "language": "python",
    "name": "py_write_to_table"
   },
   "outputs": [],
   "source": "df.to_snowflake(\n    \"customer_reviews\",\n    if_exists=\"replace\",\n    index=False\n)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e7ff0e2f-7762-4a49-bf11-b7cf92f0efd0",
   "metadata": {
    "name": "md_query_table",
    "collapsed": false
   },
   "source": "## 5. Query table"
  },
  {
   "cell_type": "code",
   "id": "fa5aae6f-d9f7-48a9-91ff-47be62380899",
   "metadata": {
    "language": "sql",
    "name": "sql_query_table"
   },
   "outputs": [],
   "source": "SELECT * FROM AVALANCHE_DB.AVALANCHE_SCHEMA.CUSTOMER_REVIEWS;",
   "execution_count": null
  }
 ]
}